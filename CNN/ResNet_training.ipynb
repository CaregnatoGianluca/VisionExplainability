{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06478cbe",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'DatasetLoader'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mDatasetLoader\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcub\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CUB\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m init\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'DatasetLoader'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "from torchvision import models\n",
    "import os\n",
    "import numpy as np\n",
    "from DatasetLoader.cub import CUB\n",
    "from torch.nn import init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf11d1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COSTANTI\n",
    "DEFAULT_BATCH_SIZE   = 64\n",
    "DEFAULT_BASE_LR      = 0.001\n",
    "DEFAULT_EPOCHS       = 95\n",
    "DEFAULT_MOMENTUM     = 0.9\n",
    "DEFAULT_WEIGHT_DECAY = 1e-4\n",
    "DEFAULT_GPU_ID       = 0\n",
    "DEFAULT_IMG_SIZE     = 448\n",
    "\n",
    "MODEL_CHOICES        = [50, 101, 152]\n",
    "\n",
    "\n",
    "EXPANSION = 4\n",
    "MODEL_SAVE_PATH = './model_save'\n",
    "DATASET_ROOT = '../CUB/DATASET/CUB_200_2011' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c273f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Funzione utilizzata per l'inizializzazione dei pesi della rete con il metodo di Kaiming He.\n",
    "'''\n",
    "def weight_init_kaiming(m):\n",
    "    class_names = m.__class__.__name__\n",
    "    if class_names.find('Conv') != -1:\n",
    "        init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
    "    elif class_names.find('Linear') != -1:\n",
    "        init.kaiming_normal_(m.weight.data)\n",
    "        #init.constant_(m.bias.data, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ee13eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, pre_trained=True, n_class=200, model_choice=50):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.n_class = n_class\n",
    "        self.base_model = self._model_choice(pre_trained, model_choice)\n",
    "        self.base_model.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.base_model.fc = nn.Linear(512*EXPANSION, n_class)\n",
    "        self.base_model.fc.apply(weight_init_kaiming)\n",
    "\n",
    "    def forward(self, x):\n",
    "        N = x.size(0)\n",
    "        assert x.size() == (N, 3, 448, 448)\n",
    "        x = self.base_model(x)\n",
    "        assert x.size() == (N, self.n_class)\n",
    "        return x\n",
    "\n",
    "    def _model_choice(self, pre_trained, model_choice):\n",
    "        if model_choice == 50:\n",
    "            return models.resnet50(pretrained=pre_trained)\n",
    "        elif model_choice == 101:\n",
    "            return models.resnet101(pretrained=pre_trained)\n",
    "        elif model_choice == 152:\n",
    "            return models.resnet152(pretrained=pre_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76e128e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class NetworkManager(object):\n",
    "    def __init__(self, options, path):\n",
    "        self.options = options\n",
    "        self.path = path\n",
    "        self.device = options['device']\n",
    "\n",
    "        print('Starting to prepare network and data...')\n",
    "\n",
    "        self.net = nn.DataParallel(self._net_choice(self.options['net_choice'])).to(self.device)\n",
    "        #self.net.load_state_dict(torch.load('/home/zhangyongshun/se_base_model/model_save/ResNet/backup/epoch120/ResNet50-finetune_fc_cub.pkl'))\n",
    "        print('Network is as follows:')\n",
    "        print(self.net)\n",
    "        #print(self.net.state_dict())\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.solver = torch.optim.SGD(\n",
    "            self.net.parameters(), lr=self.options['base_lr'], momentum=self.options['momentum'], weight_decay=self.options['weight_decay']\n",
    "        )\n",
    "        self.schedule = torch.optim.lr_scheduler.StepLR(self.solver, step_size=30, gamma=0.1)\n",
    "        #self.schedule = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        #    self.solver, mode='max', factor=0.1, patience=3, verbose=True, threshold=1e-4\n",
    "        #)\n",
    "\n",
    "        train_transform_list = [\n",
    "            transforms.RandomResizedCrop(self.options['img_size']),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                 std=(0.229, 0.224, 0.225))\n",
    "        ]\n",
    "        test_transforms_list = [\n",
    "            transforms.Resize(int(self.options['img_size']/0.875)),\n",
    "            transforms.CenterCrop(self.options['img_size']),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                 std=(0.229, 0.224, 0.225))\n",
    "        ]\n",
    "        \n",
    "        train_data = CUB(root=DATASET_ROOT, dataset_type='train',  transform=train_transform_list)\n",
    "        test_data = CUB(root=DATASET_ROOT, dataset_type='test',  transform=test_transforms_list)\n",
    "\n",
    "        self.train_loader = torch.utils.data.DataLoader(\n",
    "            train_data, batch_size=self.options['batch_size'], shuffle=True, num_workers=4, pin_memory=True\n",
    "        )\n",
    "        self.test_loader = torch.utils.data.DataLoader(\n",
    "            test_data, batch_size=16, shuffle=False, num_workers=4, pin_memory=True\n",
    "        )\n",
    "\n",
    "    def train(self):\n",
    "        epochs  = np.arange(1, self.options['epochs']+1)\n",
    "        test_acc = list()\n",
    "        train_acc = list()\n",
    "        print('Training process starts:...')\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            print('More than one GPU are used...')\n",
    "        print('Epoch\\tTrainLoss\\tTrainAcc\\tTestAcc')\n",
    "        print('-'*50)\n",
    "        best_acc = 0.0\n",
    "        best_epoch = 0\n",
    "        self.net.train(True)\n",
    "        for epoch in range(self.options['epochs']):\n",
    "            num_correct = 0\n",
    "            train_loss_epoch = list()\n",
    "            num_total = 0\n",
    "            for imgs, labels in self.train_loader:\n",
    "                self.solver.zero_grad()\n",
    "                imgs = imgs.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                output = self.net(imgs)\n",
    "                loss = self.criterion(output, labels)\n",
    "                _, pred = torch.max(output, 1)\n",
    "                num_correct += torch.sum(pred == labels.detach_())\n",
    "                num_total += labels.size(0)\n",
    "                train_loss_epoch.append(loss.item())\n",
    "                loss.backward()\n",
    "                #nn.utils.clip_grad_norm_(self.net.parameters(), 1.0)\n",
    "                self.solver.step()\n",
    "\n",
    "            train_acc_epoch = num_correct.detach().cpu().numpy()*100 / num_total\n",
    "            avg_train_loss_epoch  = sum(train_loss_epoch)/len(train_loss_epoch)\n",
    "            test_acc_epoch = self._accuracy()\n",
    "            test_acc.append(test_acc_epoch)\n",
    "            train_acc.append(train_acc_epoch)\n",
    "            self.schedule.step()\n",
    "            if test_acc_epoch>best_acc:\n",
    "                best_acc = test_acc_epoch\n",
    "                best_epoch = epoch+1\n",
    "                print('*', end='')\n",
    "                #torch.save(self.net.state_dict(), os.path.join(self.path['model_save'], self.options['net_choice'], self.options['net_choice']+str(self.options['model_choice'])+'.pkl'))\n",
    "            print('{}\\t{:.4f}\\t{:.2f}%\\t{:.2f}%'.format(epoch+1, avg_train_loss_epoch, train_acc_epoch, test_acc_epoch))\n",
    "        plt.figure()\n",
    "        plt.plot(epochs, test_acc, color='r', label='Test Acc')\n",
    "        plt.plot(epochs, train_acc, color='b', label='Train Acc')\n",
    "\n",
    "        plt.xlabel('epochs')\n",
    "        plt.ylabel('Acc')\n",
    "        plt.legend()\n",
    "        plt.title(self.options['net_choice']+str(self.options['model_choice']))\n",
    "        plt.savefig(self.options['net_choice']+str(self.options['model_choice'])+'.png')\n",
    "\n",
    "    def _accuracy(self):\n",
    "        self.net.eval()\n",
    "        num_total = 0\n",
    "        num_acc = 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in self.test_loader:\n",
    "                imgs = imgs.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                output = self.net(imgs)\n",
    "                _, pred = torch.max(output, 1)\n",
    "                num_acc += torch.sum(pred==labels.detach_())\n",
    "                num_total += labels.size(0)\n",
    "        return num_acc.detach().cpu().numpy()*100/num_total\n",
    "\n",
    "    def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "        torch.save(state, filename)\n",
    "        if is_best:\n",
    "            shutil.copyfile(filename, 'model_best.pth.tar')\n",
    "\n",
    "    def _net_choice(self, net_choice):\n",
    "        if net_choice=='ResNet':\n",
    "            return ResNet(pre_trained=True, n_class=200, model_choice=self.options['model_choice'])\n",
    "        # elif net_choice=='ResNet_ED':\n",
    "        #     return ResNet_ED(pre_trained=True, pre_trained_weight_gpu=True, n_class=200, model_choice=self.options['model_choice'])\n",
    "        # elif net_choice == 'ResNet_SE':\n",
    "        #     return ResNet_SE(pre_trained=True, pre_trained_weight_gpu=True, n_class=200, model_choice=self.options['model_choice'])\n",
    "        # elif net_choice == 'ResNet_self':\n",
    "        #     return ResNet_self(pre_trained=True, pre_trained_weight_gpu=True, n_class=200, model_choice=self.options['model_choice'])\n",
    "\n",
    "    def adjust_learning_rate(optimizer, epoch, args):\n",
    "        \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "        lr = args.lr * (0.1 ** (epoch // 30))\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db699c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to prepare network and data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MarcoStefani\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\MarcoStefani\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to C:\\Users\\MarcoStefani/.cache\\torch\\hub\\checkpoints\\resnet50-0676ba61.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 76.8M/97.8M [00:11<00:03, 6.79MB/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m      1\u001b[39m options = {\n\u001b[32m      2\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mnet_choice\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mResNet\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      3\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmodel_choice\u001b[39m\u001b[33m'\u001b[39m: MODEL_CHOICES[\u001b[32m0\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     10\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mdevice\u001b[39m\u001b[33m'\u001b[39m: torch.device(\u001b[33m'\u001b[39m\u001b[33mcuda:\u001b[39m\u001b[33m'\u001b[39m+\u001b[38;5;28mstr\u001b[39m(DEFAULT_GPU_ID) \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     11\u001b[39m }\n\u001b[32m     13\u001b[39m path = {\n\u001b[32m     14\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m'\u001b[39m: DATASET_ROOT,\n\u001b[32m     15\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmodel_save\u001b[39m\u001b[33m'\u001b[39m: MODEL_SAVE_PATH\n\u001b[32m     16\u001b[39m }\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m manager = \u001b[43mNetworkManager\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m manager.train()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mNetworkManager.__init__\u001b[39m\u001b[34m(self, options, path)\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mself\u001b[39m.device = options[\u001b[33m'\u001b[39m\u001b[33mdevice\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mStarting to prepare network and data...\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28mself\u001b[39m.net = nn.DataParallel(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_net_choice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mnet_choice\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m).to(\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m#self.net.load_state_dict(torch.load('/home/zhangyongshun/se_base_model/model_save/ResNet/backup/epoch120/ResNet50-finetune_fc_cub.pkl'))\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mNetwork is as follows:\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 121\u001b[39m, in \u001b[36mNetworkManager._net_choice\u001b[39m\u001b[34m(self, net_choice)\u001b[39m\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_net_choice\u001b[39m(\u001b[38;5;28mself\u001b[39m, net_choice):\n\u001b[32m    120\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m net_choice==\u001b[33m'\u001b[39m\u001b[33mResNet\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mResNet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpre_trained\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_class\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_choice\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmodel_choice\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mResNet.__init__\u001b[39m\u001b[34m(self, pre_trained, n_class, model_choice)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28msuper\u001b[39m(ResNet, \u001b[38;5;28mself\u001b[39m).\u001b[34m__init__\u001b[39m()\n\u001b[32m      4\u001b[39m \u001b[38;5;28mself\u001b[39m.n_class = n_class\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28mself\u001b[39m.base_model = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_model_choice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpre_trained\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_choice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mself\u001b[39m.base_model.avgpool = nn.AdaptiveAvgPool2d((\u001b[32m1\u001b[39m,\u001b[32m1\u001b[39m))\n\u001b[32m      7\u001b[39m \u001b[38;5;28mself\u001b[39m.base_model.fc = nn.Linear(\u001b[32m512\u001b[39m*EXPANSION, n_class)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mResNet._model_choice\u001b[39m\u001b[34m(self, pre_trained, model_choice)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_model_choice\u001b[39m(\u001b[38;5;28mself\u001b[39m, pre_trained, model_choice):\n\u001b[32m     18\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model_choice == \u001b[32m50\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresnet50\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpre_trained\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m model_choice == \u001b[32m101\u001b[39m:\n\u001b[32m     21\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m models.resnet101(pretrained=pre_trained)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MarcoStefani\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:142\u001b[39m, in \u001b[36mkwonly_to_pos_or_kw.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    135\u001b[39m     warnings.warn(\n\u001b[32m    136\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUsing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msequence_to_str(\u001b[38;5;28mtuple\u001b[39m(keyword_only_kwargs.keys()),\u001b[38;5;250m \u001b[39mseparate_last=\u001b[33m'\u001b[39m\u001b[33mand \u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m as positional \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    137\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    138\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33minstead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    139\u001b[39m     )\n\u001b[32m    140\u001b[39m     kwargs.update(keyword_only_kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MarcoStefani\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:228\u001b[39m, in \u001b[36mhandle_legacy_interface.<locals>.outer_wrapper.<locals>.inner_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    225\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m kwargs[pretrained_param]\n\u001b[32m    226\u001b[39m     kwargs[weights_param] = default_weights_arg\n\u001b[32m--> \u001b[39m\u001b[32m228\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbuilder\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MarcoStefani\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\resnet.py:763\u001b[39m, in \u001b[36mresnet50\u001b[39m\u001b[34m(weights, progress, **kwargs)\u001b[39m\n\u001b[32m    737\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"ResNet-50 from `Deep Residual Learning for Image Recognition <https://arxiv.org/abs/1512.03385>`__.\u001b[39;00m\n\u001b[32m    738\u001b[39m \n\u001b[32m    739\u001b[39m \u001b[33;03m.. note::\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    759\u001b[39m \u001b[33;03m    :members:\u001b[39;00m\n\u001b[32m    760\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    761\u001b[39m weights = ResNet50_Weights.verify(weights)\n\u001b[32m--> \u001b[39m\u001b[32m763\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_resnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBottleneck\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MarcoStefani\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\resnet.py:301\u001b[39m, in \u001b[36m_resnet\u001b[39m\u001b[34m(block, layers, weights, progress, **kwargs)\u001b[39m\n\u001b[32m    298\u001b[39m model = ResNet(block, layers, **kwargs)\n\u001b[32m    300\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m301\u001b[39m     model.load_state_dict(\u001b[43mweights\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprogress\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[32m    303\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MarcoStefani\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_api.py:91\u001b[39m, in \u001b[36mWeightsEnum.get_state_dict\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_state_dict\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> Mapping[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_state_dict_from_url\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MarcoStefani\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\hub.py:871\u001b[39m, in \u001b[36mload_state_dict_from_url\u001b[39m\u001b[34m(url, model_dir, map_location, progress, check_hash, file_name, weights_only)\u001b[39m\n\u001b[32m    869\u001b[39m         r = HASH_REGEX.search(filename)  \u001b[38;5;66;03m# r is Optional[Match[str]]\u001b[39;00m\n\u001b[32m    870\u001b[39m         hash_prefix = r.group(\u001b[32m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m r \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m871\u001b[39m     \u001b[43mdownload_url_to_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcached_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhash_prefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _is_legacy_zip_format(cached_file):\n\u001b[32m    874\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _legacy_zip_load(cached_file, model_dir, map_location, weights_only)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MarcoStefani\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\hub.py:748\u001b[39m, in \u001b[36mdownload_url_to_file\u001b[39m\u001b[34m(url, dst, hash_prefix, progress)\u001b[39m\n\u001b[32m    740\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(\n\u001b[32m    741\u001b[39m     total=file_size,\n\u001b[32m    742\u001b[39m     disable=\u001b[38;5;129;01mnot\u001b[39;00m progress,\n\u001b[32m   (...)\u001b[39m\u001b[32m    745\u001b[39m     unit_divisor=\u001b[32m1024\u001b[39m,\n\u001b[32m    746\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[32m    747\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m748\u001b[39m         buffer = \u001b[43mu\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mREAD_DATA_CHUNK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    749\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buffer) == \u001b[32m0\u001b[39m:\n\u001b[32m    750\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MarcoStefani\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:479\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt > \u001b[38;5;28mself\u001b[39m.length:\n\u001b[32m    477\u001b[39m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[32m    478\u001b[39m     amt = \u001b[38;5;28mself\u001b[39m.length\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m s = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[32m    481\u001b[39m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[32m    482\u001b[39m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[32m    483\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_conn()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MarcoStefani\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\socket.py:720\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    719\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m720\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    721\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    722\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MarcoStefani\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:1251\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1247\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1248\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1249\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1250\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1252\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1253\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MarcoStefani\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:1103\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1101\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1102\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1103\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1104\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1105\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "options = {\n",
    "    'net_choice': \"ResNet\",\n",
    "    'model_choice': MODEL_CHOICES[0],\n",
    "    'epochs': DEFAULT_EPOCHS,\n",
    "    'batch_size': DEFAULT_BATCH_SIZE,\n",
    "    'base_lr': DEFAULT_BASE_LR,\n",
    "    'weight_decay': DEFAULT_WEIGHT_DECAY,\n",
    "    'momentum': DEFAULT_MOMENTUM,\n",
    "    'img_size': DEFAULT_IMG_SIZE,\n",
    "    'device': torch.device('cuda:'+str(DEFAULT_GPU_ID) if torch.cuda.is_available() else 'cpu')\n",
    "}\n",
    "\n",
    "path = {\n",
    "    'data': DATASET_ROOT,\n",
    "    'model_save': MODEL_SAVE_PATH\n",
    "}\n",
    "  \n",
    "manager = NetworkManager(options, path)\n",
    "manager.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
