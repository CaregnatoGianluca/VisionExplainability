{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06478cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add parent directory to path so we can import DatasetLoader\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "from torchvision import models\n",
    "from DatasetLoader.cub_v2 import cub200\n",
    "from torch.nn import init"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c215c3de",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf11d1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COSTANTI\n",
    "DEFAULT_BATCH_SIZE   = 64\n",
    "DEFAULT_BASE_LR      = 0.001\n",
    "DEFAULT_EPOCHS       = 95\n",
    "DEFAULT_MOMENTUM     = 0.9\n",
    "DEFAULT_WEIGHT_DECAY = 1e-4\n",
    "DEFAULT_GPU_ID       = 0\n",
    "DEFAULT_IMG_SIZE     = 448\n",
    "\n",
    "MODEL_CHOICES        = [50, 101, 152]\n",
    "\n",
    "\n",
    "EXPANSION = 4\n",
    "MODEL_SAVE_PATH = './model_save'\n",
    "DATASET_ROOT = '../CUB/DATASET/CUB_200_2011' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c273f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Funzione utilizzata per l'inizializzazione dei pesi della rete con il metodo di Kaiming He.\n",
    "'''\n",
    "def weight_init_kaiming(m):\n",
    "    class_names = m.__class__.__name__\n",
    "    if class_names.find('Conv') != -1:\n",
    "        init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
    "    elif class_names.find('Linear') != -1:\n",
    "        init.kaiming_normal_(m.weight.data)\n",
    "        #init.constant_(m.bias.data, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ee13eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, pre_trained=True, n_class=200, model_choice=50):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.n_class = n_class\n",
    "        self.base_model = self._model_choice(pre_trained, model_choice)\n",
    "        self.base_model.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.base_model.fc = nn.Linear(512*EXPANSION, n_class)\n",
    "        self.base_model.fc.apply(weight_init_kaiming)\n",
    "\n",
    "    def forward(self, x):\n",
    "        N = x.size(0)\n",
    "        assert x.size() == (N, 3, 448, 448)\n",
    "        x = self.base_model(x)\n",
    "        assert x.size() == (N, self.n_class)\n",
    "        return x\n",
    "\n",
    "    def _model_choice(self, pre_trained, model_choice):\n",
    "        if model_choice == 50:\n",
    "            return models.resnet50(pretrained=pre_trained)\n",
    "        elif model_choice == 101:\n",
    "            return models.resnet101(pretrained=pre_trained)\n",
    "        elif model_choice == 152:\n",
    "            return models.resnet152(pretrained=pre_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76e128e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from DatasetLoader.cub_v2 import cub200\n",
    "\n",
    "\n",
    "class NetworkManager(object):\n",
    "    def __init__(self, options, path):\n",
    "        self.options = options\n",
    "        self.path = path\n",
    "        self.device = options['device']\n",
    "\n",
    "        print('Starting to prepare network and data...')\n",
    "\n",
    "        self.net = nn.DataParallel(self._net_choice(self.options['net_choice'])).to(self.device)\n",
    "        #self.net.load_state_dict(torch.load('/home/zhangyongshun/se_base_model/model_save/ResNet/backup/epoch120/ResNet50-finetune_fc_cub.pkl'))\n",
    "        print('Network is as follows:')\n",
    "        print(self.net)\n",
    "        #print(self.net.state_dict())\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.solver = torch.optim.SGD(\n",
    "            self.net.parameters(), lr=self.options['base_lr'], momentum=self.options['momentum'], weight_decay=self.options['weight_decay']\n",
    "        )\n",
    "        self.schedule = torch.optim.lr_scheduler.StepLR(self.solver, step_size=30, gamma=0.1)\n",
    "        #self.schedule = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        #    self.solver, mode='max', factor=0.1, patience=3, verbose=True, threshold=1e-4\n",
    "        #)\n",
    "\n",
    "        train_transform_list = [\n",
    "            transforms.RandomResizedCrop(self.options['img_size']),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                 std=(0.229, 0.224, 0.225))\n",
    "        ]\n",
    "        test_transforms_list = [\n",
    "            transforms.Resize(int(self.options['img_size']/0.875)),\n",
    "            transforms.CenterCrop(self.options['img_size']),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                 std=(0.229, 0.224, 0.225))\n",
    "        ]\n",
    "        \n",
    "        # train_data = CUB(root=DATASET_ROOT, dataset_type='train',  transform=train_transform_list)\n",
    "        # test_data = CUB(root=DATASET_ROOT, dataset_type='test',  transform=test_transforms_list)\n",
    "        train_data = cub200(self.path['data'], train=True, transform=transforms.Compose(train_transform_list))\n",
    "        test_data = cub200(self.path['data'], train=False, transform=transforms.Compose(test_transforms_list))\n",
    "        \n",
    "        self.train_loader = torch.utils.data.DataLoader(\n",
    "            train_data, batch_size=self.options['batch_size'], shuffle=True, num_workers=4, pin_memory=True\n",
    "        )\n",
    "        self.test_loader = torch.utils.data.DataLoader(\n",
    "            test_data, batch_size=16, shuffle=False, num_workers=4, pin_memory=True\n",
    "        )\n",
    "\n",
    "    def train(self):\n",
    "        epochs  = np.arange(1, self.options['epochs']+1)\n",
    "        test_acc = list()\n",
    "        train_acc = list()\n",
    "        print('Training process starts:...')\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            print('More than one GPU are used...')\n",
    "        print('Epoch\\tTrainLoss\\tTrainAcc\\tTestAcc')\n",
    "        print('-'*50)\n",
    "        best_acc = 0.0\n",
    "        best_epoch = 0\n",
    "        self.net.train(True)\n",
    "        for epoch in range(self.options['epochs']):\n",
    "            num_correct = 0\n",
    "            train_loss_epoch = list()\n",
    "            num_total = 0\n",
    "            for imgs, labels in self.train_loader:\n",
    "                self.solver.zero_grad()\n",
    "                imgs = imgs.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                output = self.net(imgs)\n",
    "                loss = self.criterion(output, labels)\n",
    "                _, pred = torch.max(output, 1)\n",
    "                num_correct += torch.sum(pred == labels.detach_())\n",
    "                num_total += labels.size(0)\n",
    "                train_loss_epoch.append(loss.item())\n",
    "                loss.backward()\n",
    "                #nn.utils.clip_grad_norm_(self.net.parameters(), 1.0)\n",
    "                self.solver.step()\n",
    "\n",
    "            train_acc_epoch = num_correct.detach().cpu().numpy()*100 / num_total\n",
    "            avg_train_loss_epoch  = sum(train_loss_epoch)/len(train_loss_epoch)\n",
    "            test_acc_epoch = self._accuracy()\n",
    "            test_acc.append(test_acc_epoch)\n",
    "            train_acc.append(train_acc_epoch)\n",
    "            self.schedule.step()\n",
    "            if test_acc_epoch>best_acc:\n",
    "                best_acc = test_acc_epoch\n",
    "                best_epoch = epoch+1\n",
    "                print('*', end='')\n",
    "                torch.save(self.net.state_dict(), os.path.join(self.path['model_save'], self.options['net_choice'], self.options['net_choice']+str(self.options['model_choice'])+'.pkl'))\n",
    "                \n",
    "            print('{}\\t{:.4f}\\t{:.2f}%\\t{:.2f}%'.format(epoch+1, avg_train_loss_epoch, train_acc_epoch, test_acc_epoch))\n",
    "        plt.figure()\n",
    "        plt.plot(epochs, test_acc, color='r', label='Test Acc')\n",
    "        plt.plot(epochs, train_acc, color='b', label='Train Acc')\n",
    "\n",
    "        plt.xlabel('epochs')\n",
    "        plt.ylabel('Acc')\n",
    "        plt.legend()\n",
    "        plt.title(self.options['net_choice']+str(self.options['model_choice']))\n",
    "        # plt.savefig(self.options['net_choice']+str(self.options['model_choice'])+'.png')\n",
    "\n",
    "    def _accuracy(self):\n",
    "        self.net.eval()\n",
    "        num_total = 0\n",
    "        num_acc = 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in self.test_loader:\n",
    "                imgs = imgs.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                output = self.net(imgs)\n",
    "                _, pred = torch.max(output, 1)\n",
    "                num_acc += torch.sum(pred==labels.detach_())\n",
    "                num_total += labels.size(0)\n",
    "        return num_acc.detach().cpu().numpy()*100/num_total\n",
    "\n",
    "    def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "        torch.save(state, filename)\n",
    "        if is_best:\n",
    "            shutil.copyfile(filename, 'model_best.pth.tar')\n",
    "\n",
    "    def load_checkpoint(self, checkpoint_path):\n",
    "        if os.path.isfile(checkpoint_path):\n",
    "            print(\"=> loading checkpoint '{}'\".format(checkpoint_path))\n",
    "            checkpoint = torch.load(checkpoint_path)\n",
    "            self.net.load_state_dict(checkpoint['state_dict'])\n",
    "            self.solver.load_state_dict(checkpoint['optimizer'])\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(checkpoint_path, checkpoint['epoch']))\n",
    "        else:\n",
    "            print(\"=> no checkpoint found at '{}'\".format(checkpoint_path))\n",
    "    \n",
    "    def _net_choice(self, net_choice):\n",
    "        if net_choice=='ResNet':\n",
    "            return ResNet(pre_trained=True, n_class=200, model_choice=self.options['model_choice'])\n",
    "        # elif net_choice=='ResNet_ED':\n",
    "        #     return ResNet_ED(pre_trained=True, pre_trained_weight_gpu=True, n_class=200, model_choice=self.options['model_choice'])\n",
    "        # elif net_choice == 'ResNet_SE':\n",
    "        #     return ResNet_SE(pre_trained=True, pre_trained_weight_gpu=True, n_class=200, model_choice=self.options['model_choice'])\n",
    "        # elif net_choice == 'ResNet_self':\n",
    "        #     return ResNet_self(pre_trained=True, pre_trained_weight_gpu=True, n_class=200, model_choice=self.options['model_choice'])\n",
    "\n",
    "    def adjust_learning_rate(optimizer, epoch, args):\n",
    "        \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "        lr = args.lr * (0.1 ** (epoch // 30))\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db699c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to prepare network and data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gian/anaconda3/envs/VisionMamba/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/gian/anaconda3/envs/VisionMamba/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /home/gian/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "  0%|          | 0.00/97.8M [00:00<?, ?B/s]Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /home/gian/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:09<00:00, 10.3MB/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network is as follows:\n",
      "DataParallel(\n",
      "  (module): ResNet(\n",
      "    (base_model): ResNet(\n",
      "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      (layer1): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer2): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer3): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (4): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (5): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer4): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "      (fc): Linear(in_features=2048, out_features=200, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 18\u001b[0m\n\u001b[1;32m      1\u001b[0m options \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnet_choice\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResNet\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_choice\u001b[39m\u001b[38;5;124m'\u001b[39m: MODEL_CHOICES[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m: torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(DEFAULT_GPU_ID) \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m }\n\u001b[1;32m     13\u001b[0m path \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m: DATASET_ROOT,\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_save\u001b[39m\u001b[38;5;124m'\u001b[39m: MODEL_SAVE_PATH\n\u001b[1;32m     16\u001b[0m }\n\u001b[0;32m---> 18\u001b[0m manager \u001b[38;5;241m=\u001b[39m \u001b[43mNetworkManager\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m manager\u001b[38;5;241m.\u001b[39mtrain()\n",
      "Cell \u001b[0;32mIn[7], line 43\u001b[0m, in \u001b[0;36mNetworkManager.__init__\u001b[0;34m(self, options, path)\u001b[0m\n\u001b[1;32m     33\u001b[0m test_transforms_list \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     34\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mResize(\u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimg_size\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m0.875\u001b[39m)),\n\u001b[1;32m     35\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mCenterCrop(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimg_size\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m                          std\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0.229\u001b[39m, \u001b[38;5;241m0.224\u001b[39m, \u001b[38;5;241m0.225\u001b[39m))\n\u001b[1;32m     39\u001b[0m ]\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# train_data = CUB(root=DATASET_ROOT, dataset_type='train',  transform=train_transform_list)\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# test_data = CUB(root=DATASET_ROOT, dataset_type='test',  transform=test_transforms_list)\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m train_data \u001b[38;5;241m=\u001b[39m \u001b[43mcub200\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_transform_list\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m test_data \u001b[38;5;241m=\u001b[39m cub200(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m], train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, transform\u001b[38;5;241m=\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mCompose(test_transforms_list))\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(\n\u001b[1;32m     47\u001b[0m     train_data, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m], shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     48\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/explainabilityAI/DatasetLoader/cub_v2.py:19\u001b[0m, in \u001b[0;36mcub200.__init__\u001b[0;34m(self, root, train, transform)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain \u001b[38;5;241m=\u001b[39m train\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;241m=\u001b[39m transform\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_processed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain file has been extracted\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest file has been extracted\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/explainabilityAI/DatasetLoader/cub_v2.py:48\u001b[0m, in \u001b[0;36mcub200._check_processed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_check_processed\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUB_200_2011.tgz\u001b[39m\u001b[38;5;124m'\u001b[39m)) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessed/train.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m     50\u001b[0m             os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessed/test.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "options = {\n",
    "    'net_choice': \"ResNet\",\n",
    "    'model_choice': MODEL_CHOICES[0],\n",
    "    'epochs': DEFAULT_EPOCHS,\n",
    "    'batch_size': DEFAULT_BATCH_SIZE,\n",
    "    'base_lr': DEFAULT_BASE_LR,\n",
    "    'weight_decay': DEFAULT_WEIGHT_DECAY,\n",
    "    'momentum': DEFAULT_MOMENTUM,\n",
    "    'img_size': DEFAULT_IMG_SIZE,\n",
    "    'device': torch.device('cuda:'+str(DEFAULT_GPU_ID) if torch.cuda.is_available() else 'cpu')\n",
    "}\n",
    "\n",
    "path = {\n",
    "    'data': DATASET_ROOT,\n",
    "    'model_save': MODEL_SAVE_PATH\n",
    "}\n",
    "  \n",
    "manager = NetworkManager(options, path)\n",
    "manager.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26be83ca",
   "metadata": {},
   "source": [
    "# Explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c372e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting grad-cam\n",
      "  Downloading grad-cam-1.5.5.tar.gz (7.8 MB)\n",
      "     ---------------------------------------- 0.0/7.8 MB ? eta -:--:--\n",
      "     -- ------------------------------------- 0.5/7.8 MB 5.6 MB/s eta 0:00:02\n",
      "     ---------- ----------------------------- 2.1/7.8 MB 6.9 MB/s eta 0:00:01\n",
      "     ------------------ --------------------- 3.7/7.8 MB 7.3 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 5.2/7.8 MB 7.2 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 6.6/7.8 MB 6.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 7.8/7.8 MB 7.2 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: numpy in c:\\users\\marcostefani\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from grad-cam) (2.2.6)\n",
      "Requirement already satisfied: Pillow in c:\\users\\marcostefani\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from grad-cam) (11.3.0)\n",
      "Requirement already satisfied: torch>=1.7.1 in c:\\users\\marcostefani\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from grad-cam) (2.8.0)\n",
      "Requirement already satisfied: torchvision>=0.8.2 in c:\\users\\marcostefani\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from grad-cam) (0.23.0)\n",
      "Collecting ttach (from grad-cam)\n",
      "  Downloading ttach-0.0.3-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\marcostefani\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from grad-cam) (4.67.1)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\marcostefani\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from grad-cam) (4.12.0.88)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\marcostefani\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from grad-cam) (3.10.5)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\marcostefani\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from grad-cam) (1.7.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\marcostefani\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.7.1->grad-cam) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\marcostefani\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.7.1->grad-cam) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\marcostefani\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.7.1->grad-cam) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\marcostefani\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.7.1->grad-cam) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\marcostefani\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.7.1->grad-cam) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\marcostefani\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.7.1->grad-cam) (2025.5.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\marcostefani\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.7.1->grad-cam) (80.9.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\marcostefani\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->grad-cam) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\marcostefani\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->grad-cam) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\marcostefani\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->grad-cam) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\marcostefani\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->grad-cam) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\marcostefani\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->grad-cam) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\marcostefani\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->grad-cam) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\marcostefani\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->grad-cam) (2.9.0.post0)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\marcostefani\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn->grad-cam) (1.16.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\marcostefani\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn->grad-cam) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\marcostefani\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn->grad-cam) (3.6.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\marcostefani\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm->grad-cam) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\marcostefani\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->grad-cam) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\marcostefani\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy>=1.13.3->torch>=1.7.1->grad-cam) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\marcostefani\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch>=1.7.1->grad-cam) (3.0.2)\n",
      "Downloading ttach-0.0.3-py3-none-any.whl (9.8 kB)\n",
      "Building wheels for collected packages: grad-cam\n",
      "  Building wheel for grad-cam (pyproject.toml): started\n",
      "  Building wheel for grad-cam (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for grad-cam: filename=grad_cam-1.5.5-py3-none-any.whl size=44339 sha256=ef8889d71efd3755c7db83dbae768805614238502159d5446afe791ffc4d14dc\n",
      "  Stored in directory: c:\\users\\marcostefani\\appdata\\local\\pip\\cache\\wheels\\fb\\3b\\09\\2afc520f3d69bc26ae6bd87416759c820a3f7d05c1a077bbf6\n",
      "Successfully built grad-cam\n",
      "Installing collected packages: ttach, grad-cam\n",
      "Successfully installed grad-cam-1.5.5 ttach-0.0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install grad-cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c755b827",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from torchvision.models import resnet50\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---- MODEL SETUP ----\n",
    "model = ResNet(pre_trained=True, n_class=200, model_choice=50)\n",
    "model.load_checkpoint(os.path.join(MODEL_SAVE_PATH, 'ResNet', 'ResNet50.pkl'))\n",
    "model.eval()\n",
    "\n",
    "target_layers = [model.layer4[-1]]\n",
    "\n",
    "# ---- DATASET & DATALOADERS ----\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(DEFAULT_IMG_SIZE),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                         std=(0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(int(DEFAULT_IMG_SIZE / 0.875)),\n",
    "    transforms.CenterCrop(DEFAULT_IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                         std=(0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "train_data = cub200(path['data'], train=True, transform=transforms.Compose(train_transform))\n",
    "test_data = cub200(path['data'], train=False, transform=transforms.Compose(test_transform))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data, batch_size=DEFAULT_BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True\n",
    ")\n",
    "\n",
    "# ---- GET ONE IMAGE ----\n",
    "images, labels = next(iter(train_loader))\n",
    "input_tensor = images[0].unsqueeze(0)  # aggiunge dimensione batch\n",
    "target_class = labels[0].item()\n",
    "\n",
    "# ---- CONVERT IMAGE TO RGB (0-1) for visualization ----\n",
    "# rimuovi normalizzazione\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "rgb_img = images[0].permute(1, 2, 0).cpu().numpy()\n",
    "rgb_img = std * rgb_img + mean\n",
    "rgb_img = np.clip(rgb_img, 0, 1)\n",
    "\n",
    "# ---- GRAD-CAM ----\n",
    "targets = [ClassifierOutputTarget(target_class)]\n",
    "\n",
    "with GradCAM(model=model, target_layers=target_layers) as cam:\n",
    "    grayscale_cam = cam(input_tensor=input_tensor, targets=targets)\n",
    "    grayscale_cam = grayscale_cam[0, :]\n",
    "\n",
    "# ---- VISUALIZATION ----\n",
    "visualization = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)\n",
    "plt.imshow(visualization)\n",
    "plt.title(f\"Grad-CAM (Class: {target_class})\")\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VisionMamba",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
