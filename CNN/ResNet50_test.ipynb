{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a0a840c",
   "metadata": {},
   "source": [
    "vgg 16\n",
    "resnet 18, 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48dae1ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7579197ae3f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add parent directory to Python path\n",
    "current_dir = os.path.abspath('.')\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "import argparse\n",
    "import torch\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "torch.manual_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b0c615f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ROOT = '../CUB/DATASET/CUB_200_2011'  # Updated path to go up one directory\n",
    "DATASET_VALIDATION_RANDOM_SEED = 123\n",
    "BATCH_SIZE = 8\n",
    "DATASET_WORK_NUMBER = 8\n",
    "DATASET_SPLIT_RATIO = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0af46637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 4796\n",
      "Valid: 1198\n",
      "Test: 5794\n"
     ]
    }
   ],
   "source": [
    "from DatasetLoader.cub import CUB\n",
    "\n",
    "trans_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomAffine(degrees=30, translate=(0.1,0.1), scale=(0.8,1.2)),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.02),\n",
    "    transforms.RandomResizedCrop(224,scale=(0.7,1.0), ratio=(3/4, 4/3)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "trans_test = transforms.Compose([\n",
    "    # ATTENZIONE QUA NON DOVREBBE SERIVIRE IL RESIZE (?)\n",
    "    transforms.Resize((224, 224)),\n",
    "    # transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# create dataset\n",
    "train_data = CUB(DATASET_ROOT, 'train', DATASET_SPLIT_RATIO, DATASET_VALIDATION_RANDOM_SEED, transform=trans_train)\n",
    "valid_data = CUB(DATASET_ROOT, 'valid', DATASET_SPLIT_RATIO, DATASET_VALIDATION_RANDOM_SEED, transform=trans_test)\n",
    "test_data = CUB(DATASET_ROOT, 'test', 0, 0, transform=trans_test)\n",
    "\n",
    "print(\"Train: {}\".format(len(train_data)))\n",
    "print(\"Valid: {}\".format(len(valid_data)))\n",
    "print(\"Test: {}\".format(len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fe143aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloader\n",
    "train_loader = data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, drop_last=False, num_workers=DATASET_WORK_NUMBER)\n",
    "valid_loader = data.DataLoader(valid_data, batch_size=BATCH_SIZE*2, shuffle=False, num_workers=DATASET_WORK_NUMBER)\n",
    "test_loader = data.DataLoader(test_data, batch_size=BATCH_SIZE*2, shuffle=False, num_workers=DATASET_WORK_NUMBER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a74c4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteo/miniforge3/envs/mambaLRPTEST/lib/python3.10/site-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=2048, out_features=200, bias=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=200, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = resnet50(ResNet50_Weights.IMAGENET1K_V2)\n",
    "model.fc = torch.nn.Linear(in_features=2048, out_features=200, bias=True)\n",
    "\n",
    "#freeze parameters other than fc\n",
    "#for param in model.parameters():\n",
    "#    param.requires_grad = False\n",
    "#for param in model.fc.parameters():\n",
    "#    param.requires_grad = True\n",
    "print(model.fc)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec434bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, verbose=False, delta=0):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = float('inf')\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        score = -val_loss\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.val_loss_min = val_loss\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.val_loss_min = val_loss\n",
    "            self.counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92beb1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n",
    "\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.8)\n",
    "\n",
    "early_stopping = EarlyStopping(patience=10, verbose=True, delta=0.05)\n",
    "num_epochs = 1000\n",
    "train_losses, val_losses = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "898bc68f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000] → Train Loss: 5.3081 | Val Loss: 5.2619, Train Acc: 0.50% | Val Acc: 0.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteo/miniforge3/envs/mambaLRPTEST/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:204: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/1000] → Train Loss: 5.2056 | Val Loss: 8.2828, Train Acc: 1.02% | Val Acc: 0.33%\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch [3/1000] → Train Loss: 5.0700 | Val Loss: 5.0310, Train Acc: 1.02% | Val Acc: 1.34%\n",
      "Epoch [4/1000] → Train Loss: 5.0422 | Val Loss: 5.1255, Train Acc: 1.27% | Val Acc: 1.17%\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch [5/1000] → Train Loss: 4.9607 | Val Loss: 5.0643, Train Acc: 1.36% | Val Acc: 1.50%\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch [6/1000] → Train Loss: 4.9075 | Val Loss: 4.9413, Train Acc: 1.42% | Val Acc: 2.17%\n",
      "Epoch [7/1000] → Train Loss: 4.8584 | Val Loss: 4.7422, Train Acc: 2.02% | Val Acc: 2.75%\n",
      "Epoch [8/1000] → Train Loss: 4.7496 | Val Loss: 4.6678, Train Acc: 2.96% | Val Acc: 4.34%\n",
      "Epoch [9/1000] → Train Loss: 4.5753 | Val Loss: 4.5682, Train Acc: 4.32% | Val Acc: 5.26%\n",
      "Epoch [10/1000] → Train Loss: 4.4284 | Val Loss: 4.3271, Train Acc: 5.40% | Val Acc: 5.84%\n",
      "Epoch [11/1000] → Train Loss: 4.2994 | Val Loss: 4.1747, Train Acc: 5.94% | Val Acc: 7.01%\n",
      "Epoch [12/1000] → Train Loss: 4.1934 | Val Loss: 4.0680, Train Acc: 7.36% | Val Acc: 7.43%\n",
      "Epoch [13/1000] → Train Loss: 4.0823 | Val Loss: 4.0666, Train Acc: 8.19% | Val Acc: 9.18%\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch [14/1000] → Train Loss: 3.9860 | Val Loss: 4.1689, Train Acc: 9.74% | Val Acc: 10.02%\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch [15/1000] → Train Loss: 3.8680 | Val Loss: 3.9692, Train Acc: 11.63% | Val Acc: 12.27%\n",
      "Epoch [16/1000] → Train Loss: 3.8426 | Val Loss: 3.8736, Train Acc: 12.01% | Val Acc: 12.44%\n",
      "Epoch [17/1000] → Train Loss: 3.7324 | Val Loss: 3.8354, Train Acc: 13.91% | Val Acc: 14.11%\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch [18/1000] → Train Loss: 3.6383 | Val Loss: 3.7097, Train Acc: 15.58% | Val Acc: 14.52%\n",
      "Epoch [19/1000] → Train Loss: 3.5547 | Val Loss: 3.6633, Train Acc: 16.12% | Val Acc: 15.53%\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch [20/1000] → Train Loss: 3.4692 | Val Loss: 3.5102, Train Acc: 17.26% | Val Acc: 18.03%\n",
      "Epoch [21/1000] → Train Loss: 3.4120 | Val Loss: 3.5295, Train Acc: 18.47% | Val Acc: 18.28%\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch [22/1000] → Train Loss: 3.3214 | Val Loss: 3.5701, Train Acc: 20.95% | Val Acc: 20.78%\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch [23/1000] → Train Loss: 3.2372 | Val Loss: 3.4387, Train Acc: 21.77% | Val Acc: 19.87%\n",
      "Epoch [24/1000] → Train Loss: 3.1670 | Val Loss: 3.4140, Train Acc: 22.81% | Val Acc: 20.12%\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch [25/1000] → Train Loss: 3.0934 | Val Loss: 3.2012, Train Acc: 24.27% | Val Acc: 22.87%\n",
      "Epoch [26/1000] → Train Loss: 3.0151 | Val Loss: 3.1456, Train Acc: 25.88% | Val Acc: 22.37%\n",
      "Epoch [27/1000] → Train Loss: 2.9760 | Val Loss: 3.0676, Train Acc: 26.96% | Val Acc: 25.88%\n",
      "Epoch [28/1000] → Train Loss: 2.8782 | Val Loss: 3.1285, Train Acc: 29.40% | Val Acc: 24.46%\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch [29/1000] → Train Loss: 2.8632 | Val Loss: 3.0219, Train Acc: 28.59% | Val Acc: 28.30%\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch [30/1000] → Train Loss: 2.8177 | Val Loss: 2.9253, Train Acc: 28.92% | Val Acc: 29.30%\n",
      "Epoch [31/1000] → Train Loss: 2.8575 | Val Loss: 3.0405, Train Acc: 29.11% | Val Acc: 27.46%\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch [32/1000] → Train Loss: 2.6952 | Val Loss: 3.0037, Train Acc: 32.96% | Val Acc: 28.13%\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch [33/1000] → Train Loss: 2.6423 | Val Loss: 2.9409, Train Acc: 33.53% | Val Acc: 29.55%\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Epoch [34/1000] → Train Loss: 2.7209 | Val Loss: 3.1622, Train Acc: 31.96% | Val Acc: 26.13%\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Epoch [35/1000] → Train Loss: 2.5655 | Val Loss: 2.7869, Train Acc: 34.22% | Val Acc: 32.22%\n",
      "Epoch [36/1000] → Train Loss: 2.6038 | Val Loss: 2.8941, Train Acc: 34.55% | Val Acc: 28.38%\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch [37/1000] → Train Loss: 2.5572 | Val Loss: 2.9590, Train Acc: 35.32% | Val Acc: 27.21%\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch [38/1000] → Train Loss: 2.5210 | Val Loss: 2.8440, Train Acc: 35.03% | Val Acc: 30.80%\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Epoch [39/1000] → Train Loss: 2.4996 | Val Loss: 2.8443, Train Acc: 36.05% | Val Acc: 31.80%\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Epoch [40/1000] → Train Loss: 2.4514 | Val Loss: 2.8444, Train Acc: 37.68% | Val Acc: 31.30%\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Epoch [41/1000] → Train Loss: 2.4261 | Val Loss: 2.7913, Train Acc: 37.16% | Val Acc: 32.64%\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Epoch [42/1000] → Train Loss: 2.3690 | Val Loss: 2.8980, Train Acc: 38.66% | Val Acc: 30.13%\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Epoch [43/1000] → Train Loss: 2.3508 | Val Loss: 2.9552, Train Acc: 39.62% | Val Acc: 32.05%\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Epoch [44/1000] → Train Loss: 2.3083 | Val Loss: 2.6215, Train Acc: 39.18% | Val Acc: 35.81%\n",
      "Epoch [45/1000] → Train Loss: 2.2999 | Val Loss: 2.7143, Train Acc: 39.93% | Val Acc: 33.72%\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch [46/1000] → Train Loss: 2.2662 | Val Loss: 2.6316, Train Acc: 41.14% | Val Acc: 35.31%\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch [47/1000] → Train Loss: 2.2049 | Val Loss: 2.6596, Train Acc: 42.01% | Val Acc: 34.39%\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Epoch [48/1000] → Train Loss: 2.1906 | Val Loss: 2.6412, Train Acc: 42.51% | Val Acc: 35.48%\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Epoch [49/1000] → Train Loss: 2.1630 | Val Loss: 2.6959, Train Acc: 44.02% | Val Acc: 34.06%\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Epoch [50/1000] → Train Loss: 2.1230 | Val Loss: 2.6465, Train Acc: 43.83% | Val Acc: 35.73%\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Epoch [51/1000] → Train Loss: 2.1275 | Val Loss: 2.4610, Train Acc: 44.12% | Val Acc: 38.81%\n",
      "Epoch [52/1000] → Train Loss: 2.0711 | Val Loss: 2.5520, Train Acc: 45.73% | Val Acc: 36.73%\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch [53/1000] → Train Loss: 2.0635 | Val Loss: 2.6218, Train Acc: 45.64% | Val Acc: 35.81%\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch [54/1000] → Train Loss: 2.0511 | Val Loss: 2.4331, Train Acc: 45.70% | Val Acc: 40.15%\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Epoch [55/1000] → Train Loss: 1.9981 | Val Loss: 2.7185, Train Acc: 47.21% | Val Acc: 33.56%\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Epoch [56/1000] → Train Loss: 1.9944 | Val Loss: 2.4702, Train Acc: 46.81% | Val Acc: 39.15%\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Epoch [57/1000] → Train Loss: 1.9924 | Val Loss: 2.4899, Train Acc: 46.62% | Val Acc: 37.15%\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Epoch [58/1000] → Train Loss: 1.9293 | Val Loss: 2.5009, Train Acc: 48.31% | Val Acc: 39.23%\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Epoch [59/1000] → Train Loss: 1.9552 | Val Loss: 2.3956, Train Acc: 47.35% | Val Acc: 39.32%\n",
      "Epoch [60/1000] → Train Loss: 1.8992 | Val Loss: 2.6070, Train Acc: 49.79% | Val Acc: 38.73%\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch [61/1000] → Train Loss: 1.9013 | Val Loss: 2.5370, Train Acc: 49.92% | Val Acc: 38.98%\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch [62/1000] → Train Loss: 1.8465 | Val Loss: 2.3726, Train Acc: 50.79% | Val Acc: 39.73%\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Epoch [63/1000] → Train Loss: 1.8689 | Val Loss: 2.4022, Train Acc: 49.65% | Val Acc: 40.73%\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Epoch [64/1000] → Train Loss: 1.8364 | Val Loss: 2.3431, Train Acc: 48.94% | Val Acc: 42.65%\n",
      "Epoch [65/1000] → Train Loss: 1.7996 | Val Loss: 2.5204, Train Acc: 51.71% | Val Acc: 39.82%\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch [66/1000] → Train Loss: 1.8264 | Val Loss: 2.4575, Train Acc: 50.98% | Val Acc: 40.90%\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch [67/1000] → Train Loss: 1.7846 | Val Loss: 2.5938, Train Acc: 51.67% | Val Acc: 39.48%\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Epoch [68/1000] → Train Loss: 1.7835 | Val Loss: 2.5204, Train Acc: 52.77% | Val Acc: 39.48%\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Epoch [69/1000] → Train Loss: 1.7749 | Val Loss: 2.4050, Train Acc: 51.36% | Val Acc: 39.57%\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Epoch [70/1000] → Train Loss: 1.7670 | Val Loss: 2.4361, Train Acc: 52.21% | Val Acc: 41.32%\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Epoch [71/1000] → Train Loss: 1.7267 | Val Loss: 2.7728, Train Acc: 52.96% | Val Acc: 37.31%\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Epoch [72/1000] → Train Loss: 1.7066 | Val Loss: 2.3518, Train Acc: 54.86% | Val Acc: 42.24%\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Epoch [73/1000] → Train Loss: 1.7269 | Val Loss: 2.3302, Train Acc: 53.09% | Val Acc: 43.07%\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Epoch [74/1000] → Train Loss: 1.6506 | Val Loss: 2.3276, Train Acc: 55.17% | Val Acc: 41.74%\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping at epoch 74\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "\n",
    "    for images, labels, _ in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, predicted = outputs.max(1)\n",
    "        train_correct += predicted.eq(labels).sum().item()\n",
    "        train_total += labels.size(0)\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    train_acc = 100 * train_correct / train_total\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_running_loss = 0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels, _ in valid_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            val_running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            val_correct += predicted.eq(labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "    val_loss = val_running_loss / len(valid_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    val_acc = 100 * val_correct / val_total\n",
    "\n",
    "    # Print the losses for each epoch\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] → Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}, Train Acc: {train_acc:.2f}% | Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "    # Step the learning rate scheduler\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    \n",
    "    early_stopping(val_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        print(f\"Early stopping at epoch {epoch+1}\")\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2d3f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = 'resnet50_cub_finetuned_all_weights_DU.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06b1f65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f50d213f",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_fine_tuned = torch.load(checkpoint_path)\n",
    "status = model.load_state_dict(checkpoint_fine_tuned, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b57b960e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Accuratezza finale: 43.94%\n"
     ]
    }
   ],
   "source": [
    "print(device)\n",
    "model.to(device)\n",
    "\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels, _ in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _ , predicted = torch.max(outputs, 1)  # ottiene la classe con punteggio massimo\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuratezza finale: {accuracy:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mambaLRPTEST",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
