{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee4b58e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0+cu128 12.8\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "import argparse\n",
    "from transformers import AutoModel, AutoTokenizer, MambaForCausalLM\n",
    "import torch\n",
    "print(torch.__version__, torch.version.cuda)\n",
    "\n",
    "from models_mamba import vim_base_patch16_224_bimambav2_final_pool_mean_abs_pos_embed_with_middle_cls_token_div2\n",
    "from mamba_lrp.model.vision_mamba import ModifiedVisionMamba\n",
    "\n",
    "from huggingface_hub import hf_hub_download"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0128ec3c",
   "metadata": {},
   "source": [
    "## Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c48e7bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ROOT = './CUB/DATASET/CUB_200_2011'\n",
    "DATASET_VALIDATION_RANDOM_SEED = 123\n",
    "BATCH_SIZE = 6\n",
    "DATASET_WORK_NUMBER = 8\n",
    "DATASET_SPLIT_RATIO = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60f6fdc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 5395\n",
      "Valid: 599\n",
      "Test: 5794\n"
     ]
    }
   ],
   "source": [
    "from DatasetLoader.cub import CUB\n",
    "\n",
    "\n",
    "trans_train = transforms.Compose([\n",
    "    # A SCELTA NOSTRA AUGUMENTATION\n",
    "    # transforms.RandomHorizontalFlip(p=0.5),\n",
    "    # transforms.RandomRotation(30),\n",
    "    \n",
    "    # ATTENZIONE QUA NON DOVREBBE SERIVIRE IL RESIZE (?)\n",
    "    # transforms.RandomResizedCrop(224, scale=(0.7, 1), ratio=(3/4, 4/3)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "trans_test = transforms.Compose([\n",
    "    # ATTENZIONE QUA NON DOVREBBE SERIVIRE IL RESIZE (?)\n",
    "    # transforms.Resize(224),\n",
    "    # transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# create dataset\n",
    "train_data = CUB(DATASET_ROOT, 'train', DATASET_SPLIT_RATIO, DATASET_VALIDATION_RANDOM_SEED, transform=trans_train)\n",
    "valid_data = CUB(DATASET_ROOT, 'valid', DATASET_SPLIT_RATIO, DATASET_VALIDATION_RANDOM_SEED, transform=trans_test)\n",
    "test_data = CUB(DATASET_ROOT, 'test', 0, 0, transform=trans_test)\n",
    "\n",
    "print(\"Train: {}\".format(len(train_data)))\n",
    "print(\"Valid: {}\".format(len(valid_data)))\n",
    "print(\"Test: {}\".format(len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ac59b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def imshow(image, label, ax=None, normalize=True):\n",
    "    \"\"\"show single along with label on an ax\"\"\"\n",
    "    \n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    image = image.numpy().transpose((1, 2, 0))\n",
    "\n",
    "    if normalize:\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        image = std * image + mean\n",
    "        image = np.clip(image, 0, 1)\n",
    "\n",
    "    ax.imshow(image)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.tick_params(axis='both', length=0)\n",
    "    ax.set_xticklabels('')\n",
    "    ax.set_yticklabels('')\n",
    "    ax.set_title(label)\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def show_samples(images, labels, nrows=2, ncols=3, title=None, normalize=True):\n",
    "    \"\"\" show multiple samples\n",
    "\n",
    "    args:\n",
    "        nrows (int, optional): number of row\n",
    "        ncols (int, optional): number of column\n",
    "        title (str, optional): title.\n",
    "        normalize (bool, optional): whether the images are normalized\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(nrows, ncols, facecolor='#ffffff', dpi=100)\n",
    "\n",
    "    # .flat: to map samples to multi-dimensional axes\n",
    "    for (ax, image, label) in zip(axes.flat, images, labels):\n",
    "        ax = imshow(image, label, ax, normalize)\n",
    "\n",
    "    fig.suptitle(title)\n",
    "    fig.tight_layout = True\n",
    "    fig.subplots_adjust(top=0.85, hspace=0.3)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7869e36",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [3, 404, 271] at entry 0 and [3, 332, 500] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# show samples\u001b[39;00m\n\u001b[1;32m      2\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mDataLoader(train_data, batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, drop_last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m----> 3\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m show_samples(images[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m6\u001b[39m], labels[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m6\u001b[39m], \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSHOW SOME SAMPLES\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/vimLRP/lib/python3.10/site-packages/torch/utils/data/dataloader.py:734\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    733\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 734\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    739\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    740\u001b[0m ):\n",
      "File \u001b[0;32m~/miniforge3/envs/vimLRP/lib/python3.10/site-packages/torch/utils/data/dataloader.py:790\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    789\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 790\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    791\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    792\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniforge3/envs/vimLRP/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/vimLRP/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:398\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    338\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[1;32m    340\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/vimLRP/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:211\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    208\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    212\u001b[0m         collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map)\n\u001b[1;32m    213\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed\n\u001b[1;32m    214\u001b[0m     ]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/vimLRP/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:212\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    208\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m--> 212\u001b[0m         \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed\n\u001b[1;32m    214\u001b[0m     ]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/vimLRP/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:155\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m--> 155\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[0;32m~/miniforge3/envs/vimLRP/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:272\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    270\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    271\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[0;32m--> 272\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [3, 404, 271] at entry 0 and [3, 332, 500] at entry 1"
     ]
    }
   ],
   "source": [
    "# show samples\n",
    "train_loader = data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n",
    "images, labels = next(iter(train_loader))\n",
    "show_samples(images[0:6], labels[0:6], 2, 3, 'SHOW SOME SAMPLES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03edb16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloader\n",
    "train_loader = data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, drop_last=False, num_workers=DATASET_WORK_NUMBER)\n",
    "valid_loader = data.DataLoader(valid_data, batch_size=BATCH_SIZE*2, shuffle=False, num_workers=DATASET_WORK_NUMBER)\n",
    "test_loader = data.DataLoader(test_data, batch_size=BATCH_SIZE*2, shuffle=False, num_workers=DATASET_WORK_NUMBER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e2dd5b",
   "metadata": {},
   "source": [
    "# Model creation (work in progress)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975fdd1f",
   "metadata": {},
   "source": [
    "#### parameters that were removed from previous versions of Mamba-ssm (and default values):\n",
    "- bimamba_type (='v2' in VisionMamba, =False in Mamba-ssm)\n",
    "- if_divide_out (=False)\n",
    "- init_layer_scale (=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f0fbdba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.gitattributes', 'README.md', 'vim_b_midclstok_81p9acc.pth']\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import list_repo_files\n",
    "\n",
    "files = list_repo_files(\"hustvl/Vim-base-midclstok\")\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa6fe35f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Mamba' object has no attribute 'bimamba_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m torch\u001b[38;5;241m.\u001b[39mserialization\u001b[38;5;241m.\u001b[39madd_safe_globals([argparse\u001b[38;5;241m.\u001b[39mNamespace])\n\u001b[1;32m      7\u001b[0m state \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(checkpoint_path)\n\u001b[0;32m----> 9\u001b[0m modified_model \u001b[38;5;241m=\u001b[39m \u001b[43mModifiedVisionMamba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzero_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m modified_model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39mbackbone\u001b[38;5;241m.\u001b[39membeddings\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/media/matteo/SSD/Data/UNI/4year/DeepLearning/mamba/MambaLRP/mamba_lrp/model/vision_mamba.py:451\u001b[0m, in \u001b[0;36mModifiedVisionMamba.__init__\u001b[0;34m(self, vim, zero_bias, layer_transforms)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead \u001b[38;5;241m=\u001b[39m ModifiedLinear(fc\u001b[38;5;241m=\u001b[39mvim\u001b[38;5;241m.\u001b[39mhead,\n\u001b[1;32m    447\u001b[0m                            transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    448\u001b[0m                            zero_bias\u001b[38;5;241m=\u001b[39mzero_bias)\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_path \u001b[38;5;241m=\u001b[39m vim\u001b[38;5;241m.\u001b[39mdrop_path\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList(\n\u001b[0;32m--> 451\u001b[0m     [\n\u001b[1;32m    452\u001b[0m         ModifiedBlock(\n\u001b[1;32m    453\u001b[0m             block,\n\u001b[1;32m    454\u001b[0m             zero_bias\u001b[38;5;241m=\u001b[39mzero_bias,\n\u001b[1;32m    455\u001b[0m             layer_transforms\u001b[38;5;241m=\u001b[39mlayer_transforms\n\u001b[1;32m    456\u001b[0m         )\n\u001b[1;32m    457\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m layer_idx, block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(vim\u001b[38;5;241m.\u001b[39mlayers)\n\u001b[1;32m    458\u001b[0m     ]\n\u001b[1;32m    459\u001b[0m )\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnorm\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m layer_transforms:\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_f \u001b[38;5;241m=\u001b[39m ModifiedRMSNorm(vim\u001b[38;5;241m.\u001b[39mnorm_f, zero_bias\u001b[38;5;241m=\u001b[39mzero_bias, transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midentity\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/media/matteo/SSD/Data/UNI/4year/DeepLearning/mamba/MambaLRP/mamba_lrp/model/vision_mamba.py:452\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead \u001b[38;5;241m=\u001b[39m ModifiedLinear(fc\u001b[38;5;241m=\u001b[39mvim\u001b[38;5;241m.\u001b[39mhead,\n\u001b[1;32m    447\u001b[0m                            transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    448\u001b[0m                            zero_bias\u001b[38;5;241m=\u001b[39mzero_bias)\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_path \u001b[38;5;241m=\u001b[39m vim\u001b[38;5;241m.\u001b[39mdrop_path\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList(\n\u001b[1;32m    451\u001b[0m     [\n\u001b[0;32m--> 452\u001b[0m         \u001b[43mModifiedBlock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m            \u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m            \u001b[49m\u001b[43mzero_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlayer_transforms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_transforms\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    457\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m layer_idx, block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(vim\u001b[38;5;241m.\u001b[39mlayers)\n\u001b[1;32m    458\u001b[0m     ]\n\u001b[1;32m    459\u001b[0m )\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnorm\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m layer_transforms:\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_f \u001b[38;5;241m=\u001b[39m ModifiedRMSNorm(vim\u001b[38;5;241m.\u001b[39mnorm_f, zero_bias\u001b[38;5;241m=\u001b[39mzero_bias, transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midentity\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/media/matteo/SSD/Data/UNI/4year/DeepLearning/mamba/MambaLRP/mamba_lrp/model/vision_mamba.py:376\u001b[0m, in \u001b[0;36mModifiedBlock.__init__\u001b[0;34m(self, block, zero_bias, layer_transforms)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresidual_in_fp32 \u001b[38;5;241m=\u001b[39m block\u001b[38;5;241m.\u001b[39mresidual_in_fp32\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfused_add_norm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 376\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmixer \u001b[38;5;241m=\u001b[39m \u001b[43mModifiedMamba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmixer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzero_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_bias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_transforms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_transforms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnorm\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m layer_transforms:\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm \u001b[38;5;241m=\u001b[39m ModifiedRMSNorm(block\u001b[38;5;241m.\u001b[39mnorm, zero_bias\u001b[38;5;241m=\u001b[39mzero_bias, transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124midentity\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \\\n\u001b[1;32m    380\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(block\u001b[38;5;241m.\u001b[39mnorm, RMSNorm) \u001b[38;5;28;01melse\u001b[39;00m ModifiedLayerNorm(block\u001b[38;5;241m.\u001b[39mnorm, zero_bias\u001b[38;5;241m=\u001b[39mzero_bias)\n",
      "File \u001b[0;32m/media/matteo/SSD/Data/UNI/4year/DeepLearning/mamba/MambaLRP/mamba_lrp/model/vision_mamba.py:167\u001b[0m, in \u001b[0;36mModifiedMamba.__init__\u001b[0;34m(self, mamba, zero_bias, layer_transforms)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_fast_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_idx \u001b[38;5;241m=\u001b[39m mamba\u001b[38;5;241m.\u001b[39mlayer_idx\n\u001b[0;32m--> 167\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbimamba_type \u001b[38;5;241m=\u001b[39m \u001b[43mmamba\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbimamba_type\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mif_devide_out \u001b[38;5;241m=\u001b[39m mamba\u001b[38;5;241m.\u001b[39mif_devide_out\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_layer_scale \u001b[38;5;241m=\u001b[39m mamba\u001b[38;5;241m.\u001b[39minit_layer_scale\n",
      "File \u001b[0;32m~/miniforge3/envs/vimLRP/lib/python3.10/site-packages/torch/nn/modules/module.py:1962\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1960\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1961\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1962\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1963\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1964\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Mamba' object has no attribute 'bimamba_type'"
     ]
    }
   ],
   "source": [
    "model = vim_base_patch16_224_bimambav2_final_pool_mean_abs_pos_embed_with_middle_cls_token_div2(pretrained=False)\n",
    "\n",
    "checkpoint_path = hf_hub_download(repo_id=\"hustvl/Vim-base-midclstok\", filename=\"vim_b_midclstok_81p9acc.pth\")\n",
    "\n",
    "torch.serialization.add_safe_globals([argparse.Namespace])\n",
    "\n",
    "state = torch.load(checkpoint_path)\n",
    "\n",
    "modified_model = ModifiedVisionMamba(model, zero_bias=True)\n",
    "modified_model.eval()\n",
    "model.backbone.embeddings.requires_grad = False\n",
    "pretrained_embeddings = model.backbone.embeddings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vimLRP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
